import OpenAI from 'openai';
import { TravelScenario } from '../types';
import { ConversationManager } from './conversationManager';
import { HebrewValidator } from './hebrewValidator';

export interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

class OpenAIService {
  private client: OpenAI;
  private conversationManager: ConversationManager | null = null;

  constructor() {
    const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
    if (!apiKey) {
      throw new Error('VITE_OPENAI_API_KEY environment variable is required');
    }
    
    this.client = new OpenAI({
      apiKey: apiKey,
      dangerouslyAllowBrowser: true, // Note: In production, use a backend proxy
    });
  }

  initializeConversation(scenarioId: string) {
    this.conversationManager = new ConversationManager(scenarioId);
  }

  async sendMessage(messages: ChatMessage[], scenario: TravelScenario, userMessage?: string): Promise<string> {
    // Update conversation context first
    if (this.conversationManager && userMessage) {
      this.conversationManager.updateContext(userMessage, true);
    }

    // Try real LLM with retries
    const response = await this.tryLLMWithRetries(messages, scenario);
    
    // Update context for AI response
    if (this.conversationManager) {
      this.conversationManager.updateContext(response, false);
      this.checkAndMarkObjectives(response);
    }

    return response;
  }

  private async tryLLMWithRetries(messages: ChatMessage[], scenario: TravelScenario, retries = 2): Promise<string> {
    for (let attempt = 0; attempt <= retries; attempt++) {
      try {
        console.log(`ğŸ¤– Attempting LLM call (attempt ${attempt + 1}/${retries + 1})`);
        
        // Get dynamic system prompt based on conversation context
        const systemPrompt = this.conversationManager 
          ? this.conversationManager.generateSystemPrompt()
          : this.getEnhancedSystemPrompt(scenario);

        // Prepare messages with enhanced system prompt
        const enhancedMessages: ChatMessage[] = [
          { role: 'system', content: systemPrompt },
          ...messages.filter(msg => msg.role !== 'system')
        ];

        console.log('ğŸ“ System prompt:', systemPrompt.substring(0, 200) + '...');
        console.log('ğŸ’¬ Messages count:', enhancedMessages.length);

        const completion = await this.client.chat.completions.create({
          model: 'gpt-4', // Fallback to GPT-4 as GPT-5 might not be available
          messages: enhancedMessages,
          max_tokens: 600,
          temperature: 0.8, // Slightly higher for more creative responses
          stream: false,
        });

        let response = completion.choices[0]?.message?.content;
        
        if (!response) {
          throw new Error('Empty response from OpenAI');
        }

        console.log('âœ… LLM Response received:', response.substring(0, 100) + '...');
        
        // Process and enhance the response
        return this.processLLMResponse(response);
        
      } catch (error) {
        console.error(`âŒ LLM attempt ${attempt + 1} failed:`, error);
        
        if (attempt === retries) {
          console.log('ğŸ”„ All LLM attempts failed, using intelligent fallback');
          return this.getIntelligentFallback(messages, scenario);
        }
        
        // Wait before retry
        await new Promise(resolve => setTimeout(resolve, 1000 * (attempt + 1)));
      }
    }
    
    return this.getIntelligentFallback(messages, scenario);
  }

  private processLLMResponse(response: string): string {
    // Validate and format Hebrew response
    if (HebrewValidator.isResponseInHebrew(response)) {
      response = HebrewValidator.validateAndFormatResponse(response);
      
      // Add business emojis for engagement
      response = HebrewValidator.addBusinessEmojis(response);
      
      // Ensure call to action based on conversation stage
      if (this.conversationManager) {
        const context = this.conversationManager.getContext();
        response = HebrewValidator.ensureCallToAction(response, context.stage);
      }
    }
    
    return response;
  }

  private getIntelligentFallback(messages: ChatMessage[], scenario: TravelScenario): string {
    console.log('ğŸ§  Generating intelligent fallback response');
    
    const lastMessage = messages[messages.length - 1];
    const userMessage = lastMessage?.content?.toLowerCase() || '';
    
    // Use conversation context for better fallback
    if (this.conversationManager) {
      const context = this.conversationManager.getContext();
      return this.getContextualFallback(userMessage, context, scenario);
    }
    
    // Basic keyword-based fallback
    return this.getEmergencyFallback(scenario);
  }

  private getContextualFallback(_userMessage: string, context: any, scenario: TravelScenario): string {
    const stage = context.stage;
    const info = context.customerInfo;
    
    // Contextual responses based on conversation stage
    if (stage === 'information-gathering') {
      if (!info.destination) {
        return '×ª×•×“×” ×¢×œ ×”×¤× ×™×”! ğŸŒ ×œ××™×–×” ×™×¢×“ ××ª× ××ª×›× × ×™× ×œ×˜×•×¡? ×× ×™ ×›××Ÿ ×œ×¢×–×•×¨ ×œ×›× ×œ×ª×›× ×Ÿ ××ª ×”× ×¡×™×¢×” ×”××•×©×œ××ª!';
      }
      if (!info.dates) {
        return `× ×”×“×¨! ${info.destination} ×–×” ×™×¢×“ ××“×”×™×! ğŸ“… ××ª×™ ××ª× ××ª×›× × ×™× ×œ×¦××ª ×œ× ×¡×™×¢×”?`;
      }
      if (!info.travelers) {
        return '××¢×•×œ×”! ğŸ‘¥ ×›××” ×× ×©×™× ×™×”×™×• ×‘× ×¡×™×¢×”? ×–×” ×™×¢×–×•×¨ ×œ×™ ×œ××¦×•× ×œ×›× ××ª ×”××¤×©×¨×•×™×•×ª ×”×˜×•×‘×•×ª ×‘×™×•×ª×¨.';
      }
    }
    
    if (stage === 'recommendations') {
      return `×‘×”×ª×‘×¡×¡ ×¢×œ ××” ×©×¡×™×¤×¨×ª× ×œ×™, ×™×© ×œ×™ ×›××” ×”×¦×¢×•×ª ××¢×•×œ×•×ª! ğŸ’ ×”×× ×ª×¨×¦×• ×œ×©××•×¢ ×¢×œ ×”××¤×©×¨×•×™×•×ª?`;
    }
    
    if (stage === 'upselling') {
      return '×× ×™ ×¨×•×¦×” ×œ×•×•×“× ×©×ª×”× ×• ××”× ×¡×™×¢×” ×”××•×©×œ××ª! ğŸŒŸ ×™×© ×›××” ×©×™×¨×•×ª×™× × ×•×¡×¤×™× ×©×™×›×•×œ×™× ×œ×©×“×¨×’ ×œ×›× ××ª ×”×—×•×•×™×”.';
    }
    
    if (stage === 'closing') {
      return '××¢×•×œ×”! ğŸ“ ×‘×•××• × ×¡×›× ××ª ×”×¤×¨×˜×™×. ××™×š ×”×›×™ × ×•×— ×œ×›× ×©××¦×•×¨ ××™×ª×›× ×§×©×¨ ×œ×”××©×š ×”×˜×™×¤×•×œ?';
    }
    
    return this.getScenarioFallback(scenario);
  }
  
  private getScenarioFallback(scenario: TravelScenario): string {
    switch (scenario) {
      case 'vacation-planning':
        return '×× ×™ ×›××Ÿ ×œ×¢×–×•×¨ ×œ×›× ×œ×ª×›× ×Ÿ ×—×•×¤×©×” ×‘×œ×ª×™ × ×©×›×—×ª! ğŸ–ï¸ ×¡×¤×¨×• ×œ×™ ×¢×œ ×”×—×œ×•× ×©×œ×›× ×•×× ×™ ××”×¤×•×š ××•×ª×• ×œ××¦×™××•×ª.';
      case 'upcoming-trip-recommendations':
        return '×”×™×™ ×“×•×“! ğŸŒŸ ×¨××™×ª×™ ××ª ×”× ×¡×™×¢×” ×”×§×¨×•×‘×” ×©×œ×š ×œ×¤×¨××’ - ×™×© ×œ×™ ×›××” ×”×¦×¢×•×ª ××™×•×—×“×•×ª ×©×—×©×‘×ª×™ ×©×™×¢× ×™×™× ×• ××•×ª×š!';
      case 'vacation-concierge':
        return '×‘×•×§×¨ ×˜×•×‘ ×¨×•× ×”! â˜€ï¸ ××™×š ×”×—×•×¤×©×” ×‘×××¡×˜×¨×“×? ×™×© ×œ×™ ×›××” ×¤×¢×™×œ×•×™×•×ª ××“×”×™××•×ª ×œ×”×¦×™×¢ ×œ×›× ×œ×”×™×•×!';
      default:
        return '×©×œ×•×! ğŸ‘‹ ×× ×™ ×¢×•×–×¨ ×”× ×¡×™×¢×•×ª ×”×—×›× ×©×œ ×§×™×©×¨×™ ×ª×¢×•×¤×”. ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×›× ×”×™×•×?';
    }
  }

  private checkAndMarkObjectives(response: string): void {
    if (!this.conversationManager) return;

    const lowerResponse = response.toLowerCase();
    
    // Check if recommendations were made
    if (lowerResponse.includes('×××œ×™×¥') || lowerResponse.includes('×”×¦×¢×”') || lowerResponse.includes('××—×™×¨')) {
      this.conversationManager.markObjectiveCompleted('recommendationsMade');
    }

    // Check if upselling was presented
    if (lowerResponse.includes('×‘×™×˜×•×—') || lowerResponse.includes('×©×“×¨×•×’') || lowerResponse.includes('×™×•×§×¨×”')) {
      this.conversationManager.markObjectiveCompleted('upsellPresented');
    }

    // Check if follow-up was mentioned
    if (lowerResponse.includes('×¤×’×™×©×”') || lowerResponse.includes('×©×™×—×”') || lowerResponse.includes('××¢×§×‘')) {
      this.conversationManager.markObjectiveCompleted('followupScheduled');
    }
  }

  private getEnhancedSystemPrompt(scenario: TravelScenario): string {
    const basePrompt = `××ª×” × ×¦×™×’ ××§×¦×•×¢×™ ×©×œ ×§×™×©×¨×™ ×ª×¢×•×¤×” - ×¡×•×›× ×•×ª ×”× ×¡×™×¢×•×ª ×”××•×‘×™×œ×” ×‘×™×©×¨××œ ×¢× 25+ ×©× ×•×ª × ×™×¡×™×•×Ÿ.

×›×œ×œ×™× ×—×©×•×‘×™×:
- ×ª××™×“ ×¢×•× ×” ×‘×¢×‘×¨×™×ª ×˜×‘×¢×™×ª ×•×¨×”×•×˜×”
- ×”×™×” ×—×, ×™×“×™×“×•×ª×™ ×•××§×¦×•×¢×™
- ×”×©×ª××© ×‘××™××•×’'×™× ×‘×¦×•×¨×” ×˜×‘×¢×™×ª
- ×”×“×’×© ××ª ×”×¢×¨×š ×•×”×—×™×¡×›×•×Ÿ ×©×œ ×§×™×©×¨×™ ×ª×¢×•×¤×”
- ×ª××™×“ ×¡×™×™× ×¢× ×©××œ×” ××• ×”×¦×¢×” ×œ×¤×¢×•×œ×”

`;
    
    switch (scenario) {
      case 'vacation-planning':
        return basePrompt + `×”×ª××—×•×ª×š: ×ª×›× ×•×Ÿ ×—×•×¤×©×•×ª ××©×¤×—×ª×™×•×ª ×•×¨×•×× ×˜×™×•×ª

××˜×¨×•×ª ×¢×¡×§×™×•×ª:
- ×œ×–×”×•×ª ×¦×¨×›×™ ×œ×§×•×— ×•×œ×”×¦×™×¢ ×—×‘×™×œ×•×ª ××•×ª×××•×ª
- ×œ×”×¦×™×¢ ×©×™×¨×•×ª×™× × ×•×¡×¤×™× (×‘×™×˜×•×—, ×”×©×›×¨×ª ×¨×›×‘, ××˜×¨×§×¦×™×•×ª)
- ×œ××¡×•×£ ×¤×¨×˜×™ ×§×©×¨ ×•×œ×”×¤× ×•×ª ×œ××•××—×™ ×”××›×™×¨×•×ª

× ×•×©××™ Upselling:
- ×©×“×¨×•×’ ××—×œ×§×ª ×˜×™×¡×”
- ××œ×•× ×•×ª ×™×•×§×¨×” ×‘××—×™×¨×™ early bird
- ×”×©×›×¨×ª ×¨×›×‘ ×¢× ×‘×™×˜×•×— ××œ×
- ×‘×™×˜×•×— × ×¡×™×¢×•×ª ××§×™×£ (×”×“×’×© ×—×©×™×‘×•×ª!)
- ×›×¨×˜×™×¡×™ ××˜×¨×§×¦×™×•×ª ××¨××©`;
        
      case 'upcoming-trip-recommendations':
        return basePrompt + `×”×ª××—×•×ª×š: ×”××œ×¦×•×ª ×™×–×•××•×ª ×•××•×ª×××•×ª ××™×©×™×ª ×œ×œ×§×•×—×•×ª ×¢× × ×¡×™×¢×•×ª ×§×¨×•×‘×•×ª

××˜×¨×•×ª ×¢×¡×§×™×•×ª:
- ×œ×–×”×•×ª ×”×–×“×× ×•×™×•×ª upsell ×× ×ª×•× ×™ ×œ×§×•×— ×§×™×™××™×
- ×œ×”×¦×™×¢ ×©×™×¨×•×ª×™× ××•×ª×××™× ×œ× ×¡×™×¢×” ×”×¡×¤×¦×™×¤×™×ª
- ×œ×—×–×§ ×§×©×¨ ×¢× ×”×œ×§×•×— ×•×œ×”×’×‘×™×¨ × ××× ×•×ª
- ×œ×”××™×¨ ×”×¦×¢×•×ª ×œ×¨×›×™×©×•×ª × ×•×¡×¤×•×ª

×©×™×¨×•×ª×™× ××•××œ×¦×™×:
- ×›×¨×˜×™×¡×™ ××˜×¨×§×¦×™×•×ª ×‘××—×™×¨ ××•×–×œ
- ×”×©×›×¨×ª ×¨×›×‘ ×™×•×§×¨×ª×™×ª
- ×¡×™×•×¨×™× VIP ××•×“×¨×›×™×
- ××¨×•×—×•×ª ×‘××¡×¢×“×•×ª ××•×‘×—×¨×•×ª
- ×‘×™×˜×•×— × ×¡×™×¢×•×ª ××•×¨×—×‘`;
        
      case 'vacation-concierge':
        return basePrompt + `×”×ª××—×•×ª×š: ×§×•× ×¡×™×™×¨×–' ×“×™×’×™×˜×œ×™ ×—×›× ×œ×œ×§×•×—×•×ª ×‘××”×œ×š ×”×—×•×¤×©×”

××˜×¨×•×ª ×¢×¡×§×™×•×ª:
- ×œ×¢×§×•×‘ ××—×¨ ×œ×§×•×—×•×ª ×•×œ×”×¦×™×¢ ×”××œ×¦×•×ª ×‘×–××Ÿ ×××ª
- ×œ××›×•×¨ ×¤×¢×™×œ×•×™×•×ª ×•×©×™×¨×•×ª×™× ×‘××”×œ×š ×”×—×•×¤×©×”
- ×œ×—×–×§ ×—×•×•×™×ª ×”×œ×§×•×— ×•×œ×‘× ×•×ª × ××× ×•×ª
- ×œ××¡×•×£ ××™×“×¢ ×¢×œ ×”×¢×“×¤×•×ª ×œ×¢×ª×™×“

×©×™×¨×•×ª×™ ×§×•× ×¡×™×™×¨×–':
- ×”×©×›×¨×ª ××•×¤× ×™×™× ×•×¨×›×‘×™×
- ×©×™×˜×™× ×•×˜×™×•×œ×™× ××•×“×¨×›×™×
- ×›×¨×˜×™×¡×™ ××•×–×™××•× ×™× ×•××˜×¨×§×¦×™×•×ª
- ×¡×“× ××•×ª ×•×—×•×•×™×•×ª ××•×ª× ×˜×™×•×ª
- ×”××œ×¦×•×ª ××¡×¢×“×•×ª ×•×—×™×™ ×œ×™×œ×”`;
        
      default:
        return basePrompt + '×¢×–×•×¨ ×œ×œ×§×•×— ×¢× ×›×œ ×¦×¨×›×™ ×”× ×¡×™×¢×” ×‘×¦×•×¨×” ××§×¦×•×¢×™×ª ×•×—××”.';
    }
  }

  getConversationContext() {
    return this.conversationManager?.getContext() || null;
  }

  // Emergency fallback - only used as absolute last resort
  private getEmergencyFallback(_scenario: TravelScenario): string {
    console.log('ğŸš¨ Using emergency fallback response - LLM completely failed');
    return '××ª× ×¦×œ ×¢×œ ×”×ª×§×œ×” ×”×˜×›× ×™×ª! ğŸ› ï¸ ×× × × ×¡×” ×©×•×‘ ××• ×¦×•×¨ ×§×©×¨ ×¢× ×”×¦×•×•×ª ×©×œ× ×• ×‘-03-123-4567 ×œ×©×™×¨×•×ª ××™×™×“×™. ×× ×—× ×• ×›××Ÿ ×œ×¢×–×•×¨ ×œ×š 24/7! ğŸ’ª';
  }
}

export const openAiService = new OpenAIService();